{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFLarT2S7BRm"
   },
   "source": [
    "# LANGUAGE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCqKttvoCPEy"
   },
   "source": [
    "**Setup: we will include a bunch of libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuJDTWHpCOmE"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import nltk\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhsNCTsgBI9f"
   },
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAq8iOBx-9jJ",
    "outputId": "67017939-0e10-43fb-e716-c5b14377d0ac"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/nh63vo9ysiura2w/dinos.txt?dl=0 && mv dinos.txt?dl=0 dinos.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty7RR-xPD_Vc"
   },
   "source": [
    "## Dinosaurus land Dataset\n",
    "\n",
    "insired by [Kulbear](https://github.com/Kulbear/deep-learning-coursera/blob/master/Sequence%20Models/Dinosaurus%20Island%20--%20Character%20level%20language%20model%20final%20-%20v3.ipynb).\n",
    "\n",
    "### Dataset and Preprocessing\n",
    "\n",
    "Read the dataset of dinosaur names, create a list of unique characters (such as a-z), and compute the dataset and vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evdjAsvFE_rj",
    "outputId": "05b59001-907d-4fec-9770-41f371518632"
   },
   "outputs": [],
   "source": [
    "names = [name.strip().lower() for name in open('dinos.txt').readlines()]\n",
    "print(names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9E8jjnoIFcs"
   },
   "source": [
    "### Bigrams + NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVHZM8hEFtDW",
    "outputId": "8b83c10a-bf3d-4dda-d9a4-79eeaad8bcad"
   },
   "outputs": [],
   "source": [
    "chars = [char for name in names for char in name]\n",
    "freq = nltk.FreqDist(chars)\n",
    "\n",
    "print(list(freq.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQDrMdDZHrpf",
    "outputId": "2d0c6525-fcec-4216-8d44-a8eafab5ad78"
   },
   "outputs": [],
   "source": [
    "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(chars))\n",
    "print(cfreq['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLzIs2-9HvTn",
    "outputId": "171ea364-aace-42a0-9fa4-73e66ad44ad3"
   },
   "outputs": [],
   "source": [
    "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)\n",
    "print('p(a, a) = %1.4f' %cprob['a'].prob('a'))\n",
    "print('p(a, b) = %1.4f' %cprob['a'].prob('b'))\n",
    "print('p(a, u) = %1.4f' %cprob['a'].prob('u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7r8FG64VH6Nb",
    "outputId": "e33a18ce-6c59-41d9-c2b5-31dc9f75ee00"
   },
   "outputs": [],
   "source": [
    "l = sum([freq[char] for char in freq])\n",
    "def unigram_prob(char):\n",
    "    return freq[char] / l\n",
    "print('p(a) = %1.4f' %unigram_prob('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "b_tecy3QH7WB",
    "outputId": "1edd5dc3-f3be-49db-dc1c-b1440fb5c581"
   },
   "outputs": [],
   "source": [
    "cprob['a'].generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLKICXrrIQLy"
   },
   "source": [
    "Write NLTK version of generating random DINASOUR NAME with length $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQ88L6i4IZ1C"
   },
   "outputs": [],
   "source": [
    "from string import ascii_lowercase # all the letters in lowercase\n",
    "\n",
    "def generate(c, n):\n",
    "    resulting_string = \"\" + c\n",
    "    for i in range(n - 1):\n",
    "        \n",
    "        max_prob = 0\n",
    "        next_c = 'z'\n",
    "        for letter in ascii_lowercase:\n",
    "           prob = cprob[resulting_string[-1]].prob(letter)\n",
    "           if prob > max_prob:\n",
    "               max_prob = prob\n",
    "               next_c = letter\n",
    "        \n",
    "        resulting_string += next_c\n",
    "\n",
    "    return resulting_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Urd51PDDXh79",
    "outputId": "50bf2c1a-1b44-4e71-e154-a57ef66dd5ae"
   },
   "outputs": [],
   "source": [
    "generate('d', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH82ZC-mIwH1"
   },
   "source": [
    "Does it really depend on $n$ characters??...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYMqsc6IIej4"
   },
   "source": [
    "## RNN VERSION\n",
    "\n",
    "# Character-Level RNN\n",
    "\n",
    "<img src=\"http://karpathy.github.io/assets/rnn/charseq.jpeg\"  width=\"500\" />\n",
    "\n",
    "An example RNN with 4-dimensional input and output layers, and a hidden layer of 3 units (neurons). This diagram shows the activations in the forward pass when the RNN is fed the characters \"hell\" as input. The output layer contains confidences the RNN assigns for the next character (vocabulary is \"h,e,l,o\"); We want the green numbers to be high and red numbers to be low.\n",
    "\n",
    "Source: [karpathy blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "### DINO Names generation\n",
    "\n",
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHwnPU-xFv8-"
   },
   "source": [
    "The characters are a-z (26 characters) plus the \"\\n\" (or newline character), which in this assignment plays a role similar to the <EOS> (or \"End of sentence\") token we had discussed in lecture, only here it indicates the end of the dinosaur name rather than the end of a sentence. In the cell below, we create a python dictionary (i.e., a hash table) to map each character to an index from 0-26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDWk1XsxGX1G",
    "outputId": "920f598b-1754-4233-f87a-f19288986210"
   },
   "outputs": [],
   "source": [
    "data = open('dinos.txt', 'r').read()\n",
    "data = data.lower()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqpB5F0OJPVn"
   },
   "source": [
    "Converse it into a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8cEK5ytI_Jw"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DinosDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with open('dinos.txt') as f:\n",
    "            content = f.read().lower()\n",
    "            self.vocab = sorted(set(content))\n",
    "            self.vocab_size = len(self.vocab)\n",
    "            self.lines = content.splitlines()\n",
    "\n",
    "        self.ch_to_idx = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "        self.idx_to_ch = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        line = self.lines[index]\n",
    "        x_str = line\n",
    "        y_str = line[1:] + '\\n'\n",
    "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
    "        y = torch.empty(len(x_str), dtype=torch.long)\n",
    "        for i, (x_ch, y_ch) in enumerate(zip(x_str, y_str)):\n",
    "            x[i][self.ch_to_idx[x_ch]] = 1\n",
    "            y[i] = self.ch_to_idx[y_ch]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIo24GZoLqX_"
   },
   "outputs": [],
   "source": [
    "dino_dataset = DinosDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xxh0NbRJg5X"
   },
   "source": [
    "### Build Model\n",
    "\n",
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKtERrl4Ja2t",
    "outputId": "b7d1fb08-49ca-4d77-b856-7e761cae4c9e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.set_printoptions(linewidth=200)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDFX3kDHJzZP"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        # define Ws, Wh and let's add dropout\n",
    "        self.Wh = nn.Linear(hidden_size + input_size, hidden_size)\n",
    "        self.Ws = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, h_prev, x):\n",
    "        stack = torch.cat([h_prev, x], dim=1)\n",
    "        h = torch.tanh(self.dropout(self.Wh(stack)))\n",
    "        \n",
    "        y = self.Ws(h)\n",
    "        return h, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksEEW7ZOKzt-"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "816AR7mmLFsD",
    "outputId": "d779bda9-fc5b-4ee6-bc3b-433be3331e29"
   },
   "outputs": [],
   "source": [
    "train_dino_dataloader = DataLoader(dino_dataset, shuffle=True)\n",
    "next(iter(train_dino_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfr0RIATKXb3"
   },
   "outputs": [],
   "source": [
    "input_size = dino_dataset.vocab_size # == 27\n",
    "hidden_size = 50\n",
    "  \n",
    "model = RNN(input_size, hidden_size, input_size).to(device)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "sgd = optim.SGD(model.parameters(), lr=1e-2) # or Adam or RSMPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9qYrykwMARf"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, objective, optimizer):\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(train_dino_dataloader):\n",
    "        loss = 0\n",
    "\n",
    "        # zero the gradient \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # define h_prev, x and y\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "\n",
    "        # symbol by symbol feed input into the model \n",
    "        for i in range(x.shape[1]):\n",
    "            h_prev, y_pred = model(h_prev, x[:, i])\n",
    "            loss += objective(y_pred, y[:, i])\n",
    "            \n",
    "        # create gradients & perform optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAseLiCMMHOn"
   },
   "outputs": [],
   "source": [
    "def train(toe_f, model, objective, optimizer, dataset='dinos', epochs=1):\n",
    "    for e in range(1, epochs + 1):\n",
    "        # update \n",
    "        print('Epoch:{}'.format(e))\n",
    "        toe_f(model, objective, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcTiLyhIMYuw"
   },
   "outputs": [],
   "source": [
    "train(train_one_epoch, model, cross_entropy, sgd, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QePMMLmMBYh"
   },
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7ZyX11lMC54"
   },
   "outputs": [],
   "source": [
    "def sample(model):\n",
    "    model.eval()\n",
    "    word_size=0\n",
    "    newline_idx = dino_dataset.ch_to_idx['\\n']\n",
    "    with torch.no_grad():\n",
    "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        x = h_prev.new_zeros([1, dino_dataset.vocab_size])\n",
    "        start_char_idx = random.randint(1, dino_dataset.vocab_size-1)\n",
    "        indices = [start_char_idx]\n",
    "        x[0, start_char_idx] = 1\n",
    "        predicted_char_idx = start_char_idx\n",
    "        \n",
    "        while predicted_char_idx != newline_idx and word_size != 50:\n",
    "            h_prev, y_pred = model(h_prev, x)\n",
    "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
    "            \n",
    "            np.random.seed(np.random.randint(1, 5000))\n",
    "            idx = np.random.choice(np.arange(dino_dataset.vocab_size), p=y_softmax_scores.cpu().numpy().ravel())\n",
    "            indices.append(idx)\n",
    "            \n",
    "            x = (y_pred == y_pred.max(1)[0]).float()\n",
    "            predicted_char_idx = idx\n",
    "            \n",
    "            word_size += 1\n",
    "        \n",
    "        if word_size == 50:\n",
    "            indices.append(newline_idx)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imzF_LUN42SI"
   },
   "outputs": [],
   "source": [
    "def print_sample(sample):\n",
    "    for idx in sample:\n",
    "        print(dino_dataset.idx_to_ch[idx], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhtgjUdknKzQ"
   },
   "outputs": [],
   "source": [
    "name = sample(model)\n",
    "print_sample(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wsjEdoJM7Vs"
   },
   "source": [
    "Add some kind of logger: at least sample, better loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNdZQawTMVdY"
   },
   "outputs": [],
   "source": [
    "# update train_one_epoch to log & visualize loss function\n",
    "def train_one_epoch_vis(model, objective, optimizer):\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(train_dino_dataloader):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for i in range(x.shape[1]):\n",
    "            h_prev, y_pred = model(h_prev, x[:, i])\n",
    "            loss += objective(y_pred, y[:, i])\n",
    "            \n",
    "        if (line_num+1) % 100 == 0:\n",
    "            print_sample(sample(model))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y99gYRoLM5O5"
   },
   "outputs": [],
   "source": [
    "train(train_one_epoch_vis, model, cross_entropy, sgd, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pbOhOqPOdN7"
   },
   "source": [
    "# Hometask. Part 1. \n",
    "(1.5 points)\n",
    "\n",
    "Implement LSTM.\n",
    "\n",
    "Evaluate on another set of data -> text generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUUUhFNilYUc"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6Ziz5LlnjV7"
   },
   "source": [
    "## FUN PART\n",
    "\n",
    "inspired by [MelLain](https://github.com/MelLain/hse-nlp/blob/master/seminars/sem5_LMs/Dinosaur%20Island%20LM.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxk6gSQmKZ3U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from lxml.html import fromstring\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezycugoWI20G"
   },
   "outputs": [],
   "source": [
    "with open('mytext.txt', 'w') as file:\n",
    "  file.write(\"\"\"Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbours would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn’t want Dudley mixing with a child like that.\n",
    "When Mr and Mrs Dursley woke up on the dull, grey Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. Mr Dursley hummed as he picked out his most boring tie for work and Mrs Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair.\n",
    "None of them noticed a large tawny owl flutter past the window.\n",
    "At half past eight, Mr Dursley picked up his briefcase, pecked Mrs Dursley on the cheek and tried to kiss Dudley goodbye but missed, because Dudley was now having a tantrum and throwing his cereal at the walls. ‘Little tyke,’ chortled Mr Dursley as he left the house. He got into his car and backed out of number four’s drive.\n",
    "It was on the corner of the street that he noticed the first sign of something peculiar – a cat reading a map. For a second, Mr Dursley didn’t realise what he had seen – then he jerked his head around to look again. There was a tabby cat standing\n",
    "2\n",
    "THE BOY WHO LIVED\n",
    "on the corner of Privet Drive, but there wasn’t a map in sight. What could he have been thinking of? It must have been a trick of the light. Mr Dursley blinked and stared at the cat. It stared back. As Mr Dursley drove around the corner and up the road, he watched the cat in his mirror. It was now reading the sign that said Privet Drive – no, looking at the sign; cats couldn’t read maps or signs. Mr Dursley gave himself a little shake and put the cat out of his mind. As he drove towards town he thought of nothing except a large order of drills he was hoping to get that day.\n",
    "But on the edge of town, drills were driven out of his mind by something else. As he sat in the usual morning traffic jam, he couldn’t help noticing that there seemed to be a lot of strangely dressed people about. People in cloaks. Mr Dursley couldn’t bear people who dressed in funny clothes – the get-ups you saw on young people! He supposed this was some stupid new fashion. He drummed his fingers on the steering wheel and his eyes fell on a huddle of these weirdos standing quite close by. They were whispering excitedly together. Mr Dursley was enraged to see that a couple of them weren’t young at all; why, that man had to be older than he was, and wearing an emerald- green cloak! The nerve of him! But then it struck Mr Dursley that this was probably some silly stunt – these people were obviously collecting for something ... yes, that would be it. The traffic moved on, and a few minutes later, Mr Dursley arrived in the Grunnings car park, his mind back on drills.\n",
    "Mr Dursley always sat with his back to the window in his office on the ninth floor. If he hadn’t, he might have found it\n",
    "3\n",
    "\n",
    "HARRY POTTER AND THE PHILOSOPHER’S STONE\n",
    "harder to concentrate on drills that morning. He didn’t see the owls swooping past in broad daylight, though people down in the street did; they pointed and gazed open-mouthed as owl after owl sped overhead. Most of them had never seen an owl even at night-time. Mr Dursley, however, had a perfectly normal, owl-free morning. He yelled at five different people. He made several important telephone calls and shouted a bit more. He was in a very good mood until lunchtime, when he thought he’d stretch his legs and walk across the road to buy himself a bun from the baker’s opposite.\n",
    "He’d forgotten all about the people in cloaks until he passed a group of them next to the baker’s. He eyed them angrily as he passed. He didn’t know why, but they made him uneasy. This lot were whispering excitedly, too, and he couldn’t see a single collecting tin. It was on his way back past them, clutching a large doughnut in a bag, that he caught a few words of what they were saying.\n",
    "‘The Potters, that’s right, that’s what I heard –’\n",
    "‘– yes, their son, Harry –’\n",
    "Mr Dursley stopped dead. Fear flooded him. He looked\n",
    "back at the whisperers as if he wanted to say something to them, but thought better of it.\n",
    "He dashed back across the road, hurried up to his office, snapped at his secretary not to disturb him, seized his telephone and had almost finished dialling his home number when he changed his mind. He put the receiver back down and stroked his moustache, thinking no, he was being stupid. Potter wasn’t such an unusual name.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "escEG08V7-YU"
   },
   "source": [
    "You can load any text in txt format, let's experiment here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cjBokuyjwhV"
   },
   "outputs": [],
   "source": [
    "sents = [sent.lower() for sent in open('mytext.txt', 'r').read().split('.')]\n",
    "print(sents[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIEP_Reoowrs"
   },
   "outputs": [],
   "source": [
    "sents_pd = pd.DataFrame(sents, columns=['text'])\n",
    "sents_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtRFh2jrrnCS"
   },
   "source": [
    "### Preprocess\n",
    "\n",
    "\n",
    "Replace punctuation, stop words and create lemmas using NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tvdVapyntKy"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nF-SeQK_n9Vs"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "punct = punctuation + '«»—…“”*№–'\n",
    "\n",
    "def lemmatize(text):\n",
    "    \n",
    "    # use word.strip(punkt), lemmatizer.lemmatize(word) to filter our text\n",
    "    lemmas = [word.strip(punct) for word in text.lower().split()]\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in lemmas if word and word not in stops]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gamTVmhsouUl"
   },
   "outputs": [],
   "source": [
    "sents_pd['lemma'] = sents_pd.text\n",
    "sents_pd.text = sents_pd.text.apply(lemmatize)\n",
    "sents_pd = sents_pd.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "mask = (sents_pd['text'].str.len() > 1)\n",
    "sents_pd = sents_pd.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xkZYnv_qxqV"
   },
   "outputs": [],
   "source": [
    "sents_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jj1hUOLmr0qq"
   },
   "source": [
    "### Embeddings\n",
    "\n",
    "Word2Vec from `gensim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afk6D81Nri0f"
   },
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for sen in sents_pd.text:\n",
    "    vocab += [nltk.word_tokenize(sen)]\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AupSZ19QsGVK"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "model = Word2Vec(vocab, size=300, window=5, min_count=5, workers=4)\n",
    "model.save('word2v.model')\n",
    "model.most_similar(u'dursley')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax1D76qlsXrv"
   },
   "source": [
    "Compare with FastText from the same library `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN_D_AljsOiV"
   },
   "outputs": [],
   "source": [
    "ft_model = FastText(vocab, size=300, min_n=5)\n",
    "ft_model.save('ft.model')\n",
    "ft_model.most_similar('dursley')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eulGSSQPu4Qy"
   },
   "source": [
    "# Hometask 2.\n",
    "\n",
    "(1 point)\n",
    "\n",
    "Find fun pretrained W2V (w2v on poetry, nature, basically whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9iOnvrIsi3x"
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeKRczoLviNf"
   },
   "source": [
    "## Sentence Embeddings\n",
    "\n",
    "+ mean Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OE1tKKqyvhff"
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(w2v.popitem()[1])\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        text = [np.mean([self.word2vec.get(word, np.zeros(self.dim)) for word in text.split()], axis=0) for text in X.text]\n",
    "        return np.stack(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cspDNfPAvGqq"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "model = Word2Vec.load(\"word2v.model\") \n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "\n",
    "mean_w2v = MeanEmbeddingVectorizer(w2v)\n",
    "mean_w2v.transform(sents_pd[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erhBZXW6wOcy"
   },
   "source": [
    "+ weighted mean Word2Vec\n",
    "\n",
    "weights from TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SugIlJhHwJKl"
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(w2v.popitem()[1])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # YOUR CODE HERE \n",
    "        text = [np.mean([self.word2vec.get(word, np.zeros(self.dim)) * self.word2weight[word] for word in text.split()], axis=0) for text in X.text]       \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9T0bQMIzwDbL"
   },
   "outputs": [],
   "source": [
    "weighted_mean_w2v = TfidfEmbeddingVectorizer(w2v)\n",
    "weighted_mean_w2v.fit(sents_pd.text.values, sents_pd.text.values).transform(sents_pd[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI1oeLI7weDh"
   },
   "source": [
    "## Doc2Vec\n",
    "\n",
    "Unlike the already trained Word2Vec model, we still need to train the Doc2Vec model. We will use the Doc2Vec model, trained on our case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7YVL3fBwfVv"
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import *\n",
    "\n",
    "splitted_texts = [text for text in sents_pd.text]\n",
    "idx = [str(i) for i in range(len(sents_pd.text.values))]\n",
    "\n",
    "docs = []\n",
    "for i in range(len(sents_pd.text.values)):\n",
    "    docs.append(TaggedDocument(splitted_texts[i], [idx[i]]))\n",
    "\n",
    "\n",
    "model = Doc2Vec(size=300, dbow_words=0, window=5, min_count=5, workers=4, alpha=0.025, min_alpha=0.01, dm=0)\n",
    "model.build_vocab(docs)\n",
    "model.train(docs, total_examples=len(docs), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "am1xVVhsw_kG"
   },
   "outputs": [],
   "source": [
    "model.save(\"doc2v.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33OIidwTxEnt"
   },
   "source": [
    "Build a vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3q34f61xGju"
   },
   "outputs": [],
   "source": [
    "class Doc2VecVectorizer(object):\n",
    "    def __init__(self, d2v_model):\n",
    "        self.d2v_model = d2v_model\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # hint: use self.d2v_model.infer_vector(text)\n",
    "        text = np.array([self.d2v_model.infer_vector(text) for text in X.text])\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHBE5L0dxLob"
   },
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec.load(\"doc2v.model\") \n",
    "\n",
    "d2v = Doc2VecVectorizer(d2v_model)\n",
    "d2v.transform(sents_pd[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqmniaVyxRkY"
   },
   "source": [
    "# Hometask 3\n",
    "\n",
    "(3 points)\n",
    "\n",
    "Find different type of context-based embeddings to use on your text and later compare to mean W2V, D2V, etc. Any model: pretrained or trained by you on some kind of data -- should provide you with sentance embeddings. Good start (ELMo or BERT or Whatever). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvwpQ5ifG1-H"
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7m949HlR5re_"
   },
   "source": [
    "# Hometask 4\n",
    "\n",
    "(4.5 points)\n",
    "\n",
    "Create the same visualization for weighted mean W2V, mean W2V and weighted W2V for Fastext/other pretrained W2V, Doc2Vec and your own other embedding: ELMo, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKLM3_Pexhzg"
   },
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxYnBQd5xgNX"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "def get_tsne_vectors(text):\n",
    "    tsne_input = pd.DataFrame(text, index=sents_pd.text)\n",
    "    tsne_vectors = tsne.fit_transform(tsne_input.values)\n",
    "    tsne_vectors = pd.DataFrame(tsne_vectors,\n",
    "                            index=pd.Index(tsne_input.index),\n",
    "                            columns=[u'x_coord', u'y_coord'])\n",
    "    return tsne_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jcEm9Zd5j1o"
   },
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet, HoverTool\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "def tsne_embed_viz(vectors, title):\n",
    "    # add our DataFrame as a ColumnDataSource for Bokeh\n",
    "    plot_data = ColumnDataSource(vectors)\n",
    "\n",
    "    # create the plot and configure the\n",
    "    # title, dimensions, and tools\n",
    "    tsne_plot = figure(title=title,\n",
    "                      plot_width = 800,\n",
    "                      plot_height = 800,\n",
    "                      tools= (u'pan, wheel_zoom, box_zoom,'\n",
    "                              u'box_select, reset'),\n",
    "                      active_scroll=u'wheel_zoom')\n",
    "\n",
    "    # add a hover tool to display words on roll-over\n",
    "    tsne_plot.add_tools( HoverTool(tooltips = [('sentence', u'@text'),\n",
    "                                              (\"(x,y)\", \"(@x_coord, @y_coord)\")] ))\n",
    "    #labels = LabelSet(x=u'x_coord', y=u'y_coord', text=u'word', y_offset=6,\n",
    "                      #text_font_size=u'8pt', text_color=u'#555555',\n",
    "                      #source=plot_data, text_align='center')\n",
    "    #tsne_plot.add_layout(labels)\n",
    "\n",
    "    # draw the words as circles on the plot\n",
    "    tsne_plot.circle(u'x_coord', u'y_coord', source=plot_data,\n",
    "                    color=u'orange', line_alpha=0.6, fill_alpha=0.3,\n",
    "                    size=5, hover_line_color=u'black')\n",
    "\n",
    "    # configure visual elements of the plot\n",
    "    tsne_plot.title.text_font_size = value(u'16pt')\n",
    "    tsne_plot.xaxis.visible = True\n",
    "    tsne_plot.yaxis.visible = True\n",
    "    # engage!\n",
    "    show(tsne_plot);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4J0iUHWRz4-"
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
